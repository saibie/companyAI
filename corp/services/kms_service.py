from corp.models import CorporateMemory, Task
from ai_core.llm_gateway import OllamaClient
from pgvector.django import L2Distance
import os
import requests
import time

# ì „ì—­ ì„ë² ë”© ëª¨ë¸ ì„¤ì •
EMBEDDING_MODEL = "nomic-embed-text" 

def get_embedding(text: str):
    """
    Ollamaë¥¼ í†µí•´ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ Pullì„ ì‹œë„í•©ë‹ˆë‹¤.
    """
    client = OllamaClient()
    
    def _attempt_embedding():
        response = client.embeddings(model=EMBEDDING_MODEL, prompt=text)
        return response.get('embedding')

    try:
        # 1ì°¨ ì‹œë„
        return _attempt_embedding()
        
    except Exception as e:
        print(f"âš ï¸ [KMS] Embedding failed initially: {e}")
        
        # ëª¨ë¸ì´ ì—†ì–´ì„œ ë°œìƒí•œ ì—ëŸ¬ì¸ì§€ í™•ì¸ (404 Not Found ë“±)
        # OllamaëŠ” ëª¨ë¸ì´ ì—†ìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        is_model_missing = "404" in str(e) or "not found" in str(e).lower()
        
        if is_model_missing:
            print(f"ğŸ“¥ [KMS] Embedding model '{EMBEDDING_MODEL}' is missing. Pulling now... (Please wait)")
            try:
                # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ)
                for progress in client.pull_model(EMBEDDING_MODEL):
                    status = progress.get('status', '')
                    # ì§„í–‰ ìƒí™© ë¡œê·¸ê°€ ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ ì¤‘ìš” ë‹¨ê³„ë§Œ ì¶œë ¥
                    if 'downloading' in status and '100%' in status: 
                        print(f"   â†³ {status}")
                
                print(f"âœ… [KMS] Model '{EMBEDDING_MODEL}' pulled successfully. Retrying embedding...")
                
                # ì ì‹œ ëŒ€ê¸° (Ollamaê°€ ëª¨ë¸ ë¡œë“œí•  ì‹œê°„ í™•ë³´)
                time.sleep(2)
                
                # 2ì°¨ ì‹œë„ (ì¬ê·€ í˜¸ì¶œ ì•„ë‹˜)
                return _attempt_embedding()
                
            except Exception as pull_error:
                print(f"âŒ [KMS] Critical: Failed to pull model '{EMBEDDING_MODEL}': {pull_error}")
                return []
        else:
            # ëª¨ë¸ ë¯¸ì‹± ì™¸ì˜ ë‹¤ë¥¸ ì—ëŸ¬ì¸ ê²½ìš°
            print(f"âŒ [KMS] Embedding Error: {e}")
            return []

def add_knowledge(owner, subject: str, content: str, source_task_id: int = None):
    """ì§€ì‹ì„ ë²¡í„°í™”í•˜ì—¬ ìœ„í‚¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
    
    # ì„ë² ë”© ì‹œë„ (ìœ„ì—ì„œ ìˆ˜ì •í•œ get_embedding í•¨ìˆ˜ê°€ í˜¸ì¶œë¨)
    vector = get_embedding(f"{subject}\n{content}")
    
    # ë²¡í„° ìƒì„± ì‹¤íŒ¨ ì‹œ (ëª¨ë¸ Pullë„ ì‹¤íŒ¨í•œ ê²½ìš°) -> None ë°˜í™˜í•˜ì—¬ í˜¸ì¶œ ì¸¡ì—ì„œ ì•Œ ìˆ˜ ìˆê²Œ í•¨
    if not vector:
        print(f"âŒ [KMS] Failed to create embedding for '{subject}'. Skipping Wiki save.")
        return None
        
    source_task = None
    if source_task_id:
        source_task = Task.objects.filter(id=source_task_id).first()

    memory = CorporateMemory.objects.create(
        owner=owner,
        subject=subject,
        content=content,
        embedding=vector,
        source_task=source_task
    )
    print(f"ğŸ“š [KMS] New knowledge added: {subject}")
    return memory

# search_wikiëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€ (get_embeddingì´ ê°•í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ìë™ ì ìš©ë¨)
def search_wiki(query: str, top_k: int = 3):
    """ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ìœ„í‚¤ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    query_vector = get_embedding(query)
    if not query_vector:
        return []

    results = CorporateMemory.objects.annotate(
        distance=L2Distance('embedding', query_vector)
    ).order_by('distance')[:top_k]
    
    return results